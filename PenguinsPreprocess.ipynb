{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexjochs/ECE_539_Penguins/blob/preprocess/PenguinsPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjyEyhfEEczD",
        "outputId": "c7128232-c798-4083-b87a-911b73745d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Alex\n",
        "# drive.mount('/content/gdrive')\n",
        "# gdrive_data_filepath = r\"/content/gdrive/MyDrive/'Penguin_counting'/data_peng_watch\"\n",
        "# Oscar\n",
        "drive.mount('/content/drive')\n",
        "gdrive_data_filepath = r'/content/drive/MyDrive/Colab\\ Notebooks/539\\ Project/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsV513awVrjd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage.filters import gaussian_filter \n",
        "import scipy\n",
        "from scipy.spatial import KDTree\n",
        "import h5py\n",
        "import time\n",
        "from PIL import Image\n",
        "import glob\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-WUgAd0WF7v"
      },
      "outputs": [],
      "source": [
        "MASTER_LIST = ['BAILa', 'DAMOa', 'HALFb', 'HALFc', 'LOCKb', 'MAIVb', 'MAIVc', 'NEKOa', 'NEKOb', 'NEKOc', 'PETEc', 'PETEd', 'PETEf', 'SPIGa', 'GEORa']\n",
        "VM_ROOT = r'/content'\n",
        "cwd = None\n",
        "def get_new_batch(target=None):\n",
        "    assert target is not None, f\"can't get specific folder: {target} and load all data\"\n",
        "    tgz_name = target + '.tgz'\n",
        "    folder_path = os.path.join(gdrive_data_filepath, tgz_name)\n",
        "    !tar --gunzip --extract --file={folder_path} --directory {VM_ROOT}\n",
        "    cwd = os.path.join(VM_ROOT, target)\n",
        "\n",
        "def save_batch_to_drive(target=None):\n",
        "    # take working files, save them back to Gdrive\n",
        "    assert target is not None, f\"can't get specific folder: {target} and load all data\"\n",
        "    tgz_name = target + '.tgz'\n",
        "    folder_path = os.path.join(VM_ROOT, target)\n",
        "    # Oscar\n",
        "    os.chdir('/content/drive/MyDrive/Colab Notebooks/539 Project/data') \n",
        "    # Alex\n",
        "    # os.chdir(gdrive_data_filepath)\n",
        "    # !tar -czvf {tgz_name} -P {folder_path} # Verbose\n",
        "    !tar -czf {tgz_name} -P {folder_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW-k_xXHWiZc"
      },
      "outputs": [],
      "source": [
        "annotations_path = VM_ROOT + r'/CompleteAnnotations_2016-07-11'\n",
        "\n",
        "def run_all():\n",
        "    json_filepath_list = get_json_files_from_folder()\n",
        "    for filepath in json_filepath_list:\n",
        "        df = run(filepath_=filepath)\n",
        "        save_df_as_json(df)\n",
        "\n",
        "def run(filepath_=None, target=None):\n",
        "    if target is not None:\n",
        "        filepath_ = annotations_path + r'/' + target + '.json'\n",
        "    data_group_name = filepath_[-10:-5]\n",
        "    df = load_json_as_df(filepath_)\n",
        "    df.loc[df.xy.isnull(), 'xy'] = [[]]\n",
        "    # have to check if inner list has na values as well :/\n",
        "    df_xy_ = df['xy']\n",
        "    for index, value in df_xy_.items():\n",
        "        if len(value) > 0:\n",
        "            while '_NaN_' in value:\n",
        "                value.remove('_NaN_')\n",
        "                df_xy_.at[index] = value\n",
        "            while None in value:\n",
        "                value.remove(None)\n",
        "                df_xy_.at[index] = value\n",
        "            if len(value) == 0:\n",
        "                df_xy_.at[index] = [[]]\n",
        "        else:\n",
        "            df_xy_.at[index] = [[]]\n",
        "    # df_xy_ = to_1D(df['xy'])\n",
        "    # if df_xy_.isna().sum() > 0:\n",
        "    #     df_xy_na_mask = df_xy_.isna()\n",
        "    #     df.loc[df_xy_na_mask, 'xy'] = [[]]\n",
        "    df['xy'] = df_xy_\n",
        "    return df\n",
        "\n",
        "def save_df_as_json(df):\n",
        "    data_group_filename = df['imName'].iloc[0][:5] + '.json'\n",
        "    try:\n",
        "        os.mkdir('/content/annotations')\n",
        "    except FileExistsError as e:\n",
        "        print('looks like local annotations folder already exists!')\n",
        "    print(data_group_filename)\n",
        "    with open(os.path.join('/content/annotations', data_group_filename), 'w') as json_file:\n",
        "        json.dump(json.loads(df.to_json(orient='records')), json_file)\n",
        "\n",
        "def get_json_files_from_folder():\n",
        "    json_filepath_list = []\n",
        "    for filename in os.listdir(annotations_path):\n",
        "        f = os.path.join(annotations_path, filename)\n",
        "        if os.path.isfile(f):\n",
        "            file_extension = os.path.splitext(f)[1]\n",
        "        if file_extension == '.json':\n",
        "            json_filepath_list.append(f)\n",
        "    return json_filepath_list\n",
        "\n",
        "def load_json_as_df(filepath):\n",
        "    with open(filepath,'r') as json_file:\n",
        "        json_data = json.loads(json_file.read())\n",
        "    return pd.json_normalize(json_data, record_path =['dots'])\n",
        "\n",
        "def to_1D(series):\n",
        "    return pd.Series([x for _list in series for x in _list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kQuIbI08WsIb"
      },
      "outputs": [],
      "source": [
        "# dots: 2d list of xy dots from users\n",
        "# return longest (ie most penguins clicked) 1d list\n",
        "def get_longest_dot_list(dots):\n",
        "    if len(dots) == 0:\n",
        "        return []\n",
        "    idx = 0\n",
        "    if len(dots) > 1:\n",
        "        for i, x in enumerate(dots):\n",
        "            if type(x[0]) != type(0):\n",
        "                if len(x) >= len(dots[idx]):\n",
        "                    idx = i\n",
        "    return dots[idx]\n",
        "\n",
        "# One hot encoding of user clicks\n",
        "def make_sparse_mat(img_shape, dots):\n",
        "    mat = np.zeros((img_shape[1], img_shape[0]))\n",
        "\n",
        "    # Check for 1-D case TODO\n",
        "    if type(dots[0]) == type(0):\n",
        "        mat[dots[1], dots[0]] = 1\n",
        "    else:\n",
        "        for dot in dots:\n",
        "            if not (dot[0] > 800 or dot[1] > 600 or dot[0] < 0 or dot[1] < 0):\n",
        "                mat[dot[1], dot[0]] = 1\n",
        "\n",
        "    return mat\n",
        "\n",
        "def downsample_dots(dots, img_shape):\n",
        "    \"\"\"convert xy coords of annotations down to 600x800 img space\"\"\"\n",
        "    ds_dots = []\n",
        "    x_scaler = 800.0 / float(img_shape[0])\n",
        "    y_scaler = 600.0 / float(img_shape[1])\n",
        "\n",
        "    # Check for empty dots list case\n",
        "    if len(dots) == 0:\n",
        "        return []\n",
        "\n",
        "    # Check for 1-D case TODO\n",
        "    if type(dots[0]) == type(0):\n",
        "        return [math.floor(dots[0] * x_scaler), math.floor(dots[1] * y_scaler)]\n",
        "\n",
        "    for dot in dots:\n",
        "        try:\n",
        "            if dot[0] >= img_shape[0] or dot[1] >= img_shape[1] or dot[0] < 0 or dot[1] < 0: # if == could we just subtract one? i.e. [2048, 1536] - > [2047, 1535]\n",
        "                # print('DOT OUT OF RANGE:', dot) TODO\n",
        "                continue\n",
        "            ds_dots.append([math.floor(dot[0] * x_scaler), math.floor(dot[1] * y_scaler)]) # TODO\n",
        "        except:\n",
        "            print('ERROR -', dot) # TODO\n",
        "        \n",
        "    return ds_dots\n",
        "\n",
        "def gaussian_filter_density(gt):\n",
        "    #Generates a density map using Gaussian filter transformation\n",
        "    \n",
        "    density = np.zeros(gt.shape, dtype=np.float32)\n",
        "    \n",
        "    gt_count = np.count_nonzero(gt)\n",
        "    \n",
        "    if gt_count == 0:\n",
        "        return density\n",
        "\n",
        "    # FInd out the K nearest neighbours using a KDTree\n",
        "    \n",
        "    pts = np.array(list(zip(np.nonzero(gt)[1].ravel(), np.nonzero(gt)[0].ravel())))\n",
        "    leafsize = 2048\n",
        "    \n",
        "    # build kdtree\n",
        "    tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)\n",
        "    \n",
        "    # query kdtree\n",
        "    distances, locations = tree.query(pts, k=4)\n",
        "\n",
        "        \n",
        "    for i, pt in enumerate(pts):\n",
        "        pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
        "        pt2d[pt[1],pt[0]] = 1.\n",
        "        if gt_count > 1:\n",
        "            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
        "        else:\n",
        "            sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
        "        \n",
        "        #Convolve with the gaussian filter\n",
        "        \n",
        "        # density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
        "        input_ = np.fft.fft2(pt2d)\n",
        "        result = scipy.ndimage.fourier_gaussian(input_, sigma)\n",
        "        density = np.add(density, np.fft.ifft2(result).real, casting=\"unsafe\")\n",
        "    \n",
        "    return density"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7JSbZh4Cv0j"
      },
      "source": [
        "some ideas to improve speed:  \n",
        "- load all images into memory\n",
        "- downsample images to input size\n",
        "- - w/ fft, down to 4 sec!\n",
        "- use mutiprocessing to speed up execution\n",
        "- use fft instead of gaussian filter?\n",
        "- - It works! down to 35 sec per image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS7t8qWWuTnA"
      },
      "source": [
        "Cell below loads image sizes into original image data dict, which is something like {'BAILa': (2048, 1536), 'DAMOa': (2048, 1536), 'HALFb': (2048, 1536), 'HALFc': (1920, 1080), etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x40SzGTVoSJK"
      },
      "outputs": [],
      "source": [
        "# TODO I think we still want this\n",
        "original_img_dim = {'BAILa': (2048, 1536), 'DAMOa': (2048, 1536), 'HALFb': (2048, 1536), 'HALFc': (1920, 1080), 'LOCKb': (1920, 1080), 'MAIVb': (2048, 1536), 'MAIVc': (2048, 1536), 'NEKOa': (1920, 1080), 'NEKOb': (2048, 1536), 'NEKOc': (2048, 1536), 'PETEc': (2048, 1536), 'PETEd': (2048, 1536), 'PETEf': (2048, 1536), 'SPIGa': (1920, 1080), 'GEORa': (2048, 1536)}\n",
        "# for data_split_name in working_list:\n",
        "#     local_directory = os.path.join(VM_ROOT, data_split_name)\n",
        "#     for filename in glob.glob(local_directory + '/*.' + 'JPG'): #assuming gif\n",
        "#         im=Image.open(filename)\n",
        "#         original_img_dim[data_split_name] = (im.size[0], im.size[1])\n",
        "#         break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dY263MRlPt4"
      },
      "source": [
        "---\n",
        "The greatest of for loops:  \n",
        "- for every datasplit in the master list:\n",
        "    - get images for datasplit, load in to ram\n",
        "    - get annotations, store in a df\n",
        "    - get image size for that datasplit (each split is diff)\n",
        "    - for **every image in datasplit**:  \n",
        "        - downsample image to (600,800)\n",
        "        - downsample annotations\n",
        "        - get groundtruth of image via fft\n",
        "        - save downsampled image and downsampled groundtruth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZVYBHuyhTNt"
      },
      "outputs": [],
      "source": [
        "# Get Annotations\n",
        "get_new_batch('CompleteAnnotations_2016-07-11')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "crHDXBojrBBP"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/*_gt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nJCyvwIQuP8Z",
        "outputId": "54b6555d-2e7b-4841-9a7c-482f72d02f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py:937: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr_value = np.asarray(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved HALFc_gt.tgz\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-289c7c266897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# make gt heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mk_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_sparse_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_dots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mk_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_filter_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-bd5e105e69d4>\u001b[0m in \u001b[0;36mmake_sparse_mat\u001b[0;34m(img_shape, dots)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m800\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m600\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# slice working list to split workload between us\n",
        "working_list = MASTER_LIST[3:8] # TODO\n",
        "\n",
        "# MASTER LOOP\n",
        "for data_split_name in working_list:\n",
        "    # Get images of batch\n",
        "    if not os.path.exists(os.path.join(VM_ROOT, data_split_name)):\n",
        "        get_new_batch(data_split_name)\n",
        "    \n",
        "    # Create split dir of ground truths\n",
        "    split_dir = os.path.join(VM_ROOT, data_split_name + '_gt')\n",
        "    os.mkdir(split_dir)\n",
        "    os.chdir(split_dir)\n",
        "\n",
        "    # Get annotations as DataFrame\n",
        "    df = run(target=data_split_name)\n",
        "\n",
        "    # Create heatmap for each image\n",
        "    for i, row in df.iterrows():\n",
        "        # Get image for size to pass to downsample\n",
        "        # img = Image.open(os.path.join('/content', data_split_name, row['imName']) + '.JPG')\n",
        "        # TODO: actually reshape image?\n",
        "        # downsample dots to new img size of 600,800\n",
        "        img_dots = row['xy']\n",
        "        dots = get_longest_dot_list(img_dots)\n",
        "        ds_dots = downsample_dots(dots, original_img_dim[data_split_name])\n",
        "\n",
        "        # make gt heatmap\n",
        "        k_ds = make_sparse_mat((800, 600), ds_dots)\n",
        "        k_ds = gaussian_filter_density(k_ds)\n",
        "\n",
        "        # save file as an h5 type\n",
        "        with h5py.File(row['imName'] + '_gt.h5', 'w') as f:\n",
        "            f['density'] = k_ds\n",
        "\n",
        "    # Save ground truth zip\n",
        "    save_batch_to_drive(target=data_split_name + '_gt')\n",
        "    print('Saved', data_split_name+'_gt.tgz')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x for x in range(10)][4:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79jE-xYqMY0A",
        "outputId": "f6da2871-f2bc-48db-dca5-9df805f2e7dc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNIWE1Eq4tAm"
      },
      "outputs": [],
      "source": [
        "# # open each image\n",
        "# img = Image.open(os.path.join('/content', data_split_name, row['imName']) + '.JPG')\n",
        "# img.size\n",
        "# img = img.resize((800, 600), Image.ANTIALIAS)\n",
        "#         # image_list.append(img) TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PenguinsPreprocess.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}